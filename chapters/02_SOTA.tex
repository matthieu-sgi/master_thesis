\section{State of the art}

\subsection{Plant becoming a sensor}

\subsubsection{Human-Plant cohabitation}

Plants have a lot of benefic effects on human. The study from Charles Hall and Melinda Knuth \cite{hallUpdateLiteratureSupporting2019}
explain all the benefits of plants on our human system.
Watts and al. shows that urban "greening" (add green spaces in urban city)
increase tranquility, relieve stress and anxiety \cite{wattsEffectsGreeningUrban2017}.
An experience has been conducted in offices by Ikei and al \cite{ikeiPhysiologicalPsychologicalRelaxing2014}
to expose roses to employees. The experience showed that the "parasympathetic nervous activity was significantly higher while viewing the rose".
The subjects were more comfortable
being expose to roses than people that were not.

On top of that, we, as human, are spending 85\% of our live indoor \cite{leeInteractionIndoorPlants2015}. We are subject to the
\textit{technostress}. \textit{Technostress} is a term introduced by Brod and Craig \cite{brod1984technostress} in 1984.
Brod and Craig describe it as a modern disease caused by the inability of a person to interact and use information and communication technologies
in a healthy way \cite{ayyagariTechnostressTechnologicalAntecedents2011}. Lee and al \cite{leeInteractionIndoorPlants2015} compared
the stress caused by the doing a task on a computer to interacting with a plant (specifically transplanting it).
The computer task was increasing the level of stress (increased diastolic blood pressure and sympathetic nervous system activity for example).
The plant interaction on the other side was found to create positive feeling to the subjects. The plant is a good way of reducing
the \textit{technostress}.

Another study comes to the same conclusions. Hassan and al. \cite{hassanEffectsPlantActivity2018}
studied the effect of plant interaction on young adults subjects to
stress induced by electronic devices (similar to \textit{technostress}).
They concluded that significant differences in blood pressure occurred
between the subjects interacting with a plant (transplanting) and the
one that add to do the task on the electronic device (phone).

It's understandable that people see plants as un-stressful and not harmful. This makes them a perfect human-machine interface.


On top of that, Kellert and al. studied the benefits of adding plants and vegetation into architecture. They defined the \textit{Biophilic Design} \cite{kellertBiophilicDesignTheory2008}.
\textit{Biophilic Design} is an architectural and design approach that integrates natural elements into built environments, increasing human connection with nature \cite{downtonBiophilicDesignApplications2017}. The \textit{Biophilic Design} is based on the \textit{Biophilia Hypothesis} \cite{kellertBiophiliaHypothesis}, which posits that humans have an inborn tendency to look for connections with nature and other forms of life. \textit{Biophilic Design} ideas spread a mean to promote well-being, productivity, and sustainability in urban settings. This design philosophy incorporates natural light, ventilation, vegetation, water features, and organic materials to mimic natural environments, putting forward psychological and physiological benefits. The \textit{Biophilic Design} has, of course, been specifically studied for offices architectures (refer to figure \ref{fig:jng_room_qorvo}).

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{jng_room_qorvo.jpg}
    \caption{Example of \textit{Biophilic Design} in a co-working space in Paris. The room is called the "jungle room" and is designed to be bright and green.}
    \vspace{0.1cm}
    \label{fig:jng_room_qorvo}
\end{figure}



Research shows that \textit{Biophilic Design} improves cognitive function, reduces stress, and enhances creativity and productivity in workplace and educational places \cite{kellert2015practice}. Moreover, \textit{Biophilic Design} extends beyond design it aims to increase environmental sustainability by using nature-inspired materials and technologies that reduce energy consumption and enhance indoor air quality. The integration of living systems, such as vertical gardens and green roofs, not only improve biodiversity in urban areas but also helps regulate temperature and manage water coming from rain \cite{ryanBiophilicDesign2018a} (ref figure \ref{fig:biophilic_design}).

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{biophilic_design.png}
    \caption{\textit{Biophilia Hypothesis} architecture example. This building is the perfect example of Thermal and Airﬂow Variability from the \textit{Biophilia Hypothesis} principles (ref \citet{ryanBiophilicDesign2018a}).}
    % source: ryanBiophilicDesign2018a
    \vspace{0.1cm}
    \label{fig:biophilic_design}
\end{figure}

Recent innovations have expanded the application of \textit{Biophilic Design} in smart buildings, where sensors and digital interfaces track environmental conditions, creating dynamic environments that respond to human and ecological needs \cite{gaoIntegratingUserCenteredDesign2023}. This approach aligns with the growing trend of human-centered design in architecture, where spaces are designed to maintain physical and emotional well-being. \textit{Biophilic Design} is a critical component of the future of sustainable and health-focused architecture.

This framework aligns well with the concepts of the Internet of Plants, as both reinforcing human interactions with nature through technology.

\subsubsection{Biosensors}

The term \textit{Biosensor} refers to an analytical device (a sensor) that involves a biological sensing element \cite{vigneshvarRecentAdvancesBiosensor2016}. \textit{Biosensor} are mainly used in the healthcare, agriculture, food safety and to do environmental monitoring. Indeed, they are mainly made to measure chemical substances or biological reactions \cite{zieglerBiosensorDevelopment1998}.
At their core, \textit{Biosensors} typically consist of a bio-recognition element (enzymes, antibodies, nucleic acids, or even whole cells) and a transducer that converts biological responses into measurable signals, such as electrical, thermal, or optical signals.

Advances in bio-sensor technology have revolutionized personalized medicine and point-of-care diagnostics, with devices like glucose sensors \cite{wangRecentDevelopmentsBlood2015}, pregnancy tests, and wearable health monitors widely used today. These innovations offer real-time data and enable continuous monitoring of physiological conditions, improving disease management and patient outcomes. Beyond healthcare, \textit{Biosensors} are integral to environmental monitoring, particularly in detecting pollutants and hazardous substances, using microorganisms or plant tissues to assess soil and water quality.

The research is now progressing towards plant-based \textit{Biosensors}, which increase plants' natural capabilities to sense environmental changes such as detecting polluted soils \cite{chincinskaLeafInfiltrationPlant2021}. These \textit{Biosensors} represent a sustainable alternative to traditional silicon-based devices and align with the Internet of Plants.



\subsubsection{Human-Plant interaction}

The human plant interaction has been studied. Seow and al. \cite{seowPudicaFrameworkDesigning2022}
created a framework that is able to detect when something (and someone) interact with a plant.
However, this is not any plant, the plant used is the \textit{Mimosa Pudica}. This plant is special,
when something touches its leaves, the plant closes its leaves to protect them from the danger \cite{volkovMimosaPudicaElectrical2010}.
An electrical impulse is released and is catch by the device Seow and al. developed. The electrical
signal is easy to catch and thus can be used as actuator. However, the plant needs time and energy
to re-open the leaves. This framework also can't be generalized to other species of plants.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{pudica_framework.png}
    \caption{\textit{Pudica framework} made by Seow and al. The \textit{Mimosa Pudica} is a
        special plant that react to the interaction by closing its leaves. The framework captures the electrical impulse and then interprets that an interaction happened.}
    \vspace{0.1cm}
    \label{fig:pudica_framework}
\end{figure}

Sato and al. used the process of capacitive sensing to detect interaction with objects of our daily lives \cite{satoToucheEnhancingTouch2012}.
In this paper, they proposed a device called \textit{Touché} that use swept frequency capacitive sensing to detect touch interaction (ref figure \ref{fig:touche_architecture}) but also more complex interactions (such as interacting with a finger, the whole hand...). More complex interactions are captured using machine learning algorithm.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{touche_architecture.png}
    \caption{\textit{Touché} made by Sato and al. The \textit{Touché} architecture that is based swept frequency capacitive sensing. The user is closing the circuit by representing the ground level.}
    \vspace{0.1cm}
    \label{fig:touche_architecture}
\end{figure}


This paper doesn't apply the device to plants. Poupyrev and al. \cite{poupyrevBotanicusInteracticusInteractive2012}
used the device on plant to demonstrate the usage. This swept frequency technique is usable and better
than the previous single frequency technique as it captures more data.
In their article, Honigman and al. \cite{honigmanTechniquesSweptFrequencyb} adapted the \textit{Touché}
device to be use with an Arduino\footnote{Open source compute unit} microcontroller. This allowing people
to reproduce the set-up easily.



\subsubsection{Touch sensors}

Usual sensors uses physical properties to capture the data. For instance, in 1999, Hinckley and al. \cite{hinckleyTouchsensingInputDevices1999}
were building a touch sensor made of conductive paint. The conductive paint is used as an electrode.
In the circuit, a component is generating a 30 Hertz square signal. When the user interact with the conductive surface,
it shifts and induce delay in the square wave. The delay induce by the user hands is caused by its natural
capacitance. This circuit, however, gives a boolean output based on a threshold. The answer is \textit{touched}
or \textit{untouched}. % Evoke the "The present work has demonstrated that touch-sensing is an
% orthogonal property of input devices that does not
% necessarily have to be coupled with position sensing

When thinking of touch sensors, we think about the trackpad/touchpad that we daily use in our personal
computer. Those sensors use resistive or capacitive sensing. Both of these techniques are based on electrical
properties. Resistive sensing is based on the perturbation of the resistance in a circuit. Whereas
capacitive is based on the capacitance. Capturing those specific properties are usually the basic of
touch sensors.

For instance, Olberding and al. created a cuttable multitouch sensor based on capacitive sensor \cite{olberdingCuttableMultitouchSensor2013}.
This specific sensor allows to create something similar to a trackpad but with different shapes.

Reading the capacitance at a fixed frequency is working and is already used in our daily lives.
However, to capture more complex interaction and to rely on the data, adding another dimension of data is useful.
Swept Frequency Capacitive sensing consists on emitting a electrical signal and then read the capacitive values
similar to what a classic sensor would do. However, the electrical signal is not generated at a fix frequency
but is generated following a changing frequency.
Sato and al. introduced first this technique in the \texit{touché} device \cite{satoToucheEnhancingTouch2012}.
This allows to get richer information on the output of the device. \textit{Touché} allows then to capture
the information on a variety and a multitude of daily objects.
Indeed, searching through many frequencies make it simpler to find small changes and though different kind and type
of interactions.

\subsubsection{Humidity sensors}

In order to capture more data than only the touch interaction, we are interested into moisture sensors.

Lee and Lee \cite{leeHumiditySensorsReview2005} wrote a review on the different kind of humidity sensors. It exists many kind of humidity sensors. They expose many kinds of moisture sensors: resistive, capacitive, gravimetric, optical, piezoresistive and magnetoelastic sensors.

Resistive and capacitive moisture sensors differ mainly in their operating principles and durability. Resistive sensors measure soil moisture by detecting changes in electrical resistance between two probes inserted into the soil, with lower resistance indicating higher moisture levels. While these sensors are cost-effective and simple, they tend to degrade over time due to electrolysis, especially in saline conditions, reducing their reliability. Additionally, resistive sensors are sensitive to temperature changes, which can lead to signal drift, although they offer good sensitivity and typically exhibit a linear response to changes in moisture. In contrast, capacitive sensors work by measuring changes in the dielectric constant of the soil, without direct contact between the electrodes and the soil. This design makes capacitive sensors more durable and resistant to corrosion, offering greater long-term stability and accuracy. They are also less affected by temperature variations. However, capacitive sensors require careful design, with the ratio between the thickness of the sensitive material and the sensor geometry being crucial, as the electrodes' periodicity and the thickness of the sensitive coating layer significantly impact the sensor's response \cite{armankuzubasogluRecentStudiesHumidity2022}. Despite these complexities, capacitive sensors tend to provide more reliable and stable readings over time, though at a higher cost.


\subsubsection{Sonification}

Sonification is “the use of non-speech audio to convey information or perceptualize data” \cite{hermannListenYourData}.

The sonification has been used for a long time using the human ear sensor to interpret data. For instance, the Geiger counter is using the sonification to measure the ionizing radiation. This sensor is "beeping" and "crackling"
depending of the level of radiation.

Herman and al \cite{hermannListenYourData} created two sonification models to represent particles moving. They are
saying that the sonification is allowing a multidimensional representation of the data captured.
Humans are sensible to sounds. The sound allows a "rapid screening" because it is easier to listen to a sound than
read a graph or a text. The sound when combined with visualization is bringing more granularity and understanding.
They are also adding that we are using sound to diagnosis issues on a daily basis ; giving the example of a car
mechanic that is having a failure and that we can predict.

The sonification has been used in many projects. Ballora and al. \cite{ballora2012use} designed a project that mix the fluctuation of the stock
market with the apparition of keyword on Twitter social network. They were mapping specific and defined keyword with specific
sounds. The designed an app to be able to tweak and change the volume of the different sounds. The same procedure
is applied to the variation of the stock price.
They conducted this experiment in order to add another possible channel of information in the market place.
The traders and people working there are already flooded with visual information. This new channel could allow to
process more data.
The result were encouraging. However, this experiment rose issues. People were annoyed and disturbed by the sound.
They were lowering the volume and thus not hearing it. Some other people were just too much concentrated on
their task that they did not hear the variations.
More experiment should be conducted to refine the sound created and the level needed.

In the same direction, Ballora and al. \cite{ballora2012use} also developed a device to monitor the heart rate of people
using sonification. It takes the output of an electrocardiogram and transform it into a sound. Each of the ECG's frequencies
were pass into a filter and then given a specific sound.
The output of the sound creation is then listened to and interpreted. This application with a trained ear can help
diagnosis the sleep apnea through heart variability.


\subsubsection{Sonification on microcontrollers}

MCUs\footnote{microcontrollers} \cite{rochim2019design} is a kind of small computer.
Those devices can be used to generate sound. The most common way of doing electronical music
is to use MIDI\footnote{Musical Instrument Digital Interface} \cite{loyMusiciansMakeStandard1985}.
MIDI has been created in order to create music with digital computer. MIDI do not describe directly
the audio signal but the human actions to create the signal (such as turn the knob left, push the slider...).
MCU are able to produce those kind of directives \cite{fazendaProceedingsInternationalConference1}\cite{fazendaProceedingsInternationalConference2}.
However, the MCU can produce MIDI but MIDI does not directly generate sounds. A synthetizer is needed to create the sound
described.

For our use case of embedding the device, we look at MCU that were able to directly generate the signal
from a DAC\footnote{Digital to Analog Converter}. Projects had been conducted with many microcontrollers such as a small
8 bits AVR microcontrollers (ATmega32) \cite{hussainAVRMicrocontrollerImplementation2011}. This paper does not include limitation of
such a product but we can guess that the 8 bits microcontroller is limiting the sound quality. A larger project from Shaer and al.
\cite{shaerInteractiveCapacitiveTouch2020} is including an Arduino Mega controlling the visual effect of the project,
but also the interaction sensors. The Arduino Mega is then sending MIDI information to Teensy 3.2. The Teensy is then
generating the sound. The project is still too large to be fully embedded but the Teensy 3.2 is a promising compute unit.
The Teensy 3.2 is running at 72 MHz, way faster than the ATmega32 that is operating at 16MHz. The frequency is essential
when trying the produce sound signals.


\subsubsection{Commercial products}

Generating music from plants is not a new concept. Several commercial products are available on the market.
Looking at \textit{PlantWave} device from the eponym company, the device is able to generate sound from the plant. The device is
built using a small box with two electrodes. The electrodes are then connected to the plant. The device generates sound.
The process of sonification is not described and thus is blurry as it is a patent technology. The device is also not open-source

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{images/plant_wave_product.png}
    \caption{The PlantWave product on a demonstration picture (source from their website)}
    \vspace{0.1cm}
    \label{fig:plant_wave_product}
\end{figure}

Another commercial product is the \textit{Music of the Plants} product. How the product works is even more opaque and the company building the product
is sometimes associated with cult and esotericism. The product is also not open-source.


\subsection{Internet of Plants}

\subsubsection{The term}

The Internet of Plants in not a new word. Nevertheless, the term is not that spread around. Aliev and al. \cite{alievInternetPlantsApplication2018} evoked the word. The paper explain that the word is based on the IoT\footnote{Internet of Things}. The paper is using this word to describe a system of sensors to monitor plants and crops. This is really close to the IoT as it is using silicon made sensor to retrieve the data from the plants.

Internet of Plants is especially used for agriculture. In the paper of Steeneken and al. \cite{steenekenSensorsAgricultureInternet2023}, they are explaining that the use of specific sensors could and should be very efficient to boost the productivity of the crops.
The paper is also using talking about classic connected sensors but applied to plants.

Like the previous authors, Kitano and al. \cite{kitanoInternetPlantsIoP2022} also used this specific word for sensor connected agriculture. I think that the IoP of plants in that use is more a specific application of the IoT instead of a specific field of research.

\subsubsection{Distributed system}

The Internet of Plants relies on the paradigm of \textit{distributed systems}. Van and al. define distributed systems as " collection of autonomous computing elements that appears to its users as a single coherent system." \cite{steenDistributedSystems2017}.
Distributed systems scaled up with the improvement of computation power and networking link speed. It is now possible using networking to spread calculation power around a room or even the world and to rely on this computation power as a part of a working system. Distributed systems usually needs a transaction processing monitor (TP monitor) to balance and manage the communications and messages (ref figure \ref{fig:distrib_system_1}).

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{distrib_system_1.png}
    \caption{Role of a transaction processing monitor in a distributed system. The transaction processing monitor can be an app (python for instance), a load balancer...}
    \vspace{0.1cm}
    \label{fig:distrib_system_1}
\end{figure}

%source: p 37 from \cite{steenDistributedSystems2017}

Even if distributed systems spread up thanks to the increasing networking speed, they are far from being new. In 1985 Kleinrock and Leonard \cite{kleinrockDistributedSystems} already explained the principle of distributed systems. They get inspired by nature looking at bees that are communicating to fetch food, ants are also communicating but adding also their strength to get back the food. The brain is also a great example of gathering compute power to create a wide compute unit (ref figure \ref{fig:distrib_system_brain}).
At this time, adding computation power was a really interesting way of expanding the power on a local network.

\begin{figure}[h!]
    \centering
    \includegraphics[width=\textwidth]{distrib_system_brain.png}
    \caption{Human brain that is a distributed with compute units (the neurones) that creates and fully parallelized compute unit (the brain).}
    \vspace{0.1cm}
    \label{fig:distrib_system_brain}
\end{figure}

%source: p3 \cite{kleinrockDistributedSystems} 


Distributed system complicates the monitoring of the system and add complexities and faulty points in the system. There have been a lot of
research about the best way of linking pieces of a distributed system. Distributed system are usually based on a communication protocol such as the internet protocol (IP), bluetooth mesh or even Lora.
Relying on those already existing communication protocol ease the deployment of the application.
However, congested communication protocol or distance can introduce latencies and thus data failure and inconsistency.
It is important in a final product that the data is checked and verified.
We are them introducing the CAP (consistency, availability and partition tolerance) theorem also called Brewer theorem.
It has been introduced by Brewer in 2000 \cite{brewerRobustDistributedSystems2000}.
This theorem explains that it is impossible to have full data consistency, complete availability and partition tolerance
in a distributed system. Only two of the three capabilities can be achieved.
You always have to think about the balance and what is the most important in your system.
It was mainly thought especially for the distributed databases but can also be used for all the distributed systems that are
including a network communication.

On the monitoring side, Joyce and al. \cite{joyceMonitoringDistributedSystems} explained how to build a monitoring
on a distributed system. Monitoring in the case of a full solution is mandatory to be able to capture and react to eventual
failure on the system.


\subsubsection{Distributed instruments}

Now that we looked at what is a distributed system, we can go further in what is interesting to us and talk about distributed instrument. Tanaka wrote a chapter in the Oxford Hanbook of computer Music \cite{deanOxfordHandbookComputer2009} describing the arrival of new instruments based on sensors.
The author, in the chapter, first describe the evolution of the definition of an instrument \cite{tanaka2009sensor}.
Then the author is reviewing the new possibilities on the new instruments going through bio-signal instruments, tabletop
and surface instruments. The chapter is ending by talking about ensembles in music and then to network music.
Network music is exposed as a new generation of ensembles where you can spread the ensemble in space, playing
instruments in remote. Pushing even further, this chapter describes network instruments to not only being a replacement
of on-site music ensembles but also a new distinct mode of play.
The chapter is citing the \textit{Public Sound Objects} project from Barbosa and al. \cite{barbosaPublicSoundObjects2002}.
Barbosa and al. created a space that allows people to create music collaboratively on a wider area: The Internet.


%TODO: Expand more this

Distributed instruments are then a new way of thinking musical exhibitions and experiments. It brings a new level of possibilities.





\subsubsection{Sonification using software}

Sonification, the process of converting data into sound for interpretation, has seen significant advancements through the use of software frameworks. On this specific part of the state of the art we will focus only on softwares and applications used for sonification. Modern tools enable real-time, interactive sound generation, which is particularly useful in analyzing complex datasets across disciplines such as neuroscience, environmental monitoring, and human-computer interaction. Kramer and al. \cite{kramerSonificationReportStatusb} explored and wrote a study on the status of the sonification field.

It exists three main sonification platforms : Max/MSP, Pure Data, and SuperCollider. They all offer flexible environments for designing custom sound mappings, supporting a wide range of applications \cite{puckettePureDataAnother}\cite{mccartneyRethinkingComputerMusic2002}.

These tools often integrate algorithmic processes, sensor data, and even machine learning, producing sophisticated auditory representations that are increasingly immersive.
Both SuperCollider and Pure Data are open source projects. Also Max/MSP is only available on Windows and MacOS based machines which can be a limitation when working with sonification Linux server.

Max/MSP and Pure Data work similarly (ref figure \ref{fig:max_sine_wave} and figure \ref{fig:pd_sine_wave})

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{max_sine_wave.png}
    \caption{An example of a patch generating a sine wave on Max/MSP}
    \vspace{0.1cm}
    \label{fig:max_sine_wave}
\end{figure}
% Ref to those images: https://books.google.fr/books?hl=en&lr=&id=1KI7BAAAQBAJ&oi=fnd&pg=PP1&dq=max+msp+&ots=Qjq5K_Wka6&sig=Nv98NinaBGG9m11sZWrVzBA8xtE&redir_esc=y#v=onepage&q=max%20msp&f=false
\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{pd_sine_wave.png}
    \caption{An example of a patch generating a sine wave on Pure Data}
    \vspace{0.1cm}
    \label{fig:pd_sine_wave}
\end{figure}

SuperCollider is algorithmic based and less graphical (ref figure \ref{fig:sc_sine_wave}).

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.7\textwidth]{sc_sine_wave.png}
    \caption{An example of a patch generating a sine wave on SuperCollider}
    \vspace{0.1cm}
    \label{fig:sc_sine_wave}
\end{figure}

%source: https://doc.sccode.org/Tutorials/Getting-Started/05-Functions-and-Sound.html

%TODO: Ask Marc on how to cite images sources !

Web-based technologies, such as the Web Audio API \cite{smus2013web}, have further expanded accessibility, making interactive sonification more widespread. Peng and al. created a workstation called \textit{SIREN} based on this Web Audio API \cite{pengSIRENCaseStudy2021}. The development of the Web Audio API really eases the development of new sonification frameworks but also the collaboration between artists. It reduces the investment necessary to use sonification software as all the people already has a web browser.

Even if new tools are emerging or old tool getting upgraded, sonification struggle to be totally widespread \cite{neuhoffSonificationDoomedFail2019}. Artistic design continues to push the boundaries of how we interpret data through sound but it stills confined in research or artistic fields.